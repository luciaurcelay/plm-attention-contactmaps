# plm-attention-contactmaps
Protein language models are computational tools inspired by natural language processing techniques to analyze and understand protein sequences. Using large datasets of protein sequences, they capture patterns that represent biological functions, structures, and interactions. This enables predictions of protein folding, function, and even the design of novel proteins. These models hold potential for advancements in drug discovery, enzyme engineering, and understanding of diseases at the molecular level.

However, with pLMs being hard to interpret, there is little understood about why and how they make those predictions. The objective of this project is to analyze if the attention patterns in pLMs correlate with protein-related properties. In particular, we focus on how attention correlates with contact maps. We use the pLM ESM2 and Ubiquitin as a test protein. Code and results can be found in *main.ipynb* notebook.

*Ubiquitin protein*

Ubiquitin is a small regulatory protein found in almost all tissues of eukaryotic organisms, where it plays a crucial role in various cellular processes, most notably in protein degradation via the ubiquitin-proteasome pathway. It is composed of 76 amino acids, and its sequence is highly conserved across species due to its critical role in maintaining cellular homeostasis.

![image](https://github.com/user-attachments/assets/5a8afbf9-2346-4612-9a4e-ea3aa7b2cd60)
